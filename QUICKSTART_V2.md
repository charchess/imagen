# üöÄ Quickstart v2.0 - Multi-Mod√®les & LoRAs

Guide rapide pour utiliser les nouvelles fonctionnalit√©s v2.0.

---

## üîë 0. Configuration Optionnelle : Tokens API

**Pour mod√®les priv√©s/gated** : Voir [API_TOKENS_GUIDE.md](API_TOKENS_GUIDE.md)

```bash
# Cr√©er le fichier .env
cp .env.example .env

# √âditer et ajouter vos tokens (optionnel)
nano .env
```

**Exemple** : `.env`
```bash
HUGGINGFACE_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxx
CIVITAI_API_TOKEN=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

**Avantages** :
- ‚úÖ Acc√®s aux mod√®les HuggingFace priv√©s/gated
- ‚úÖ Pas de limite de t√©l√©chargement
- ‚úÖ Acc√®s aux LoRAs priv√©s

**Rebuild apr√®s configuration** :
```bash
docker-compose down
docker-compose up -d
```

---

## üì¶ 1. Ajouter un Nouveau Mod√®le (ex: PonyXL v6)

### Option A : Auto-t√©l√©chargement depuis HuggingFace

**Fichier** : `app/models_config.py`

```python
AVAILABLE_MODELS = {
    "sdxl-base": ModelConfig(...),  # D√©j√† configur√©

    # D√©commenter pour activer PonyXL
    "pony-xl-v6": ModelConfig(
        name="PonyXL v6",
        path="AstraliteHeart/pony-diffusion-v6-xl",
        vae_path="madebyollin/sdxl-vae-fp16-fix",
        default_negative="low quality, bad anatomy, worst quality, low res",
        description="SDXL fine-tun√© pour style anime/pony"
    ),
}
```

**Rebuild** :
```bash
docker-compose restart worker
```

Le mod√®le sera t√©l√©charg√© au **premier usage** (~6.5GB).

### Option B : Mod√®le local

1. **T√©l√©charger** le mod√®le dans `./models/pony-xl-v6/`
2. **Configurer** dans `models_config.py` :
```python
"pony-xl-v6": ModelConfig(
    name="PonyXL v6",
    path="./models/pony-xl-v6",  # Chemin local
    vae_path="madebyollin/sdxl-vae-fp16-fix",
    default_negative="low quality, bad anatomy",
    description="PonyXL local"
),
```

---

## üé® 2. Ajouter un LoRA Custom (ex: depuis Civitai)

### Exemple : LoRA Civitai

**URL Civitai** : `https://civitai.com/api/download/models/695220?type=Model&format=SafeTensor`

#### √âtape 1 : T√©l√©charger le LoRA

```bash
# Cr√©er le dossier
mkdir -p ./models/my_custom_lora

# T√©l√©charger (depuis le host, PAS le DevContainer)
cd /mnt/c/Users/TON_USER/path/to/imagen  # Adapter selon ton setup
wget -O ./models/my_custom_lora/model.safetensors \
  "https://civitai.com/api/download/models/695220?type=Model&format=SafeTensor"
```

**Alternative** : T√©l√©charger manuellement et placer dans `./models/my_custom_lora/`

#### √âtape 2 : Configurer dans `app/models_config.py`

```python
AVAILABLE_LORAS = {
    # LoRAs existants...
    "anime-style": LoRAConfig(...),
    "character-detail": LoRAConfig(...),

    # Nouveau LoRA custom
    "my-civitai-lora": LoRAConfig(
        name="My Civitai LoRA",
        path="./models/my_custom_lora",  # Chemin local
        default_weight=0.8,
        trigger_words=["specific trigger", "keywords"],  # V√©rifier sur Civitai
        description="LoRA t√©l√©charg√© depuis Civitai (Model 695220)"
    ),
}
```

#### √âtape 3 : Rebuild

```bash
docker-compose restart worker
```

---

## üß™ 3. Utiliser PonyXL + LoRA Custom

### Via API (cURL)

```bash
curl -X POST http://localhost:8009/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "a cute pony character with detailed eyes, fantasy background",
    "negative_prompt": "low quality, bad anatomy, worst quality",
    "model": "pony-xl-v6",
    "loras": [
      {
        "name": "my-civitai-lora",
        "weight": 0.8
      }
    ],
    "steps": 35,
    "guidance_scale": 7.5,
    "seed": 42
  }'
```

**R√©ponse** :
```json
{
  "job_id": "abc12345-...",
  "status": "queued",
  "message": "T√¢che en file d'attente"
}
```

### Via Python

```python
import requests
import time

API_URL = "http://localhost:8009"

# Cr√©er la g√©n√©ration
response = requests.post(f"{API_URL}/generate", json={
    "prompt": "a cute pony character with detailed eyes",
    "negative_prompt": "low quality, bad anatomy",
    "model": "pony-xl-v6",
    "loras": [
        {"name": "my-civitai-lora", "weight": 0.8}
    ],
    "steps": 35,
    "guidance_scale": 7.5,
    "seed": 42
})

job_id = response.json()["job_id"]
print(f"Job cr√©√©: {job_id}")

# Polling jusqu'√† compl√©tion
while True:
    status = requests.get(f"{API_URL}/status/{job_id}").json()

    if status["status"] == "SUCCESS":
        print(f"‚úÖ Image pr√™te: {status['result']['filename']}")

        # T√©l√©charger l'image
        image = requests.get(f"{API_URL}/image/{job_id}")
        with open("pony_output.png", "wb") as f:
            f.write(image.content)
        print("‚úÖ Image t√©l√©charg√©e: pony_output.png")
        break

    elif status["status"] == "FAILURE":
        print(f"‚ùå Erreur: {status['error']}")
        break

    else:
        print(f"‚è≥ Status: {status['status']}")
        time.sleep(5)
```

---

## üîç 4. V√©rifier les Mod√®les et LoRAs Disponibles

### Lister les mod√®les

```bash
curl http://localhost:8009/models | jq '.'
```

**R√©ponse** :
```json
{
  "models": [
    {
      "id": "sdxl-base",
      "name": "SDXL Base 1.0",
      "description": "..."
    },
    {
      "id": "pony-xl-v6",
      "name": "PonyXL v6",
      "description": "..."
    }
  ]
}
```

### Lister les LoRAs

```bash
curl http://localhost:8009/loras | jq '.'
```

**R√©ponse** :
```json
{
  "loras": [
    {
      "id": "my-civitai-lora",
      "name": "My Civitai LoRA",
      "default_weight": 0.8,
      "trigger_words": ["specific trigger", "keywords"]
    }
  ]
}
```

---

## ‚öôÔ∏è 5. Workflow Complet : PonyXL + LoRA Civitai

### R√©sum√© des √âtapes

1. **T√©l√©charger le LoRA** :
   ```bash
   mkdir -p ./models/civitai_lora_695220
   wget -O ./models/civitai_lora_695220/model.safetensors \
     "https://civitai.com/api/download/models/695220?type=Model&format=SafeTensor"
   ```

2. **√âditer `app/models_config.py`** :
   - D√©commenter `pony-xl-v6` dans `AVAILABLE_MODELS`
   - Ajouter le LoRA dans `AVAILABLE_LORAS` :
     ```python
     "civitai-695220": LoRAConfig(
         name="Civitai LoRA 695220",
         path="./models/civitai_lora_695220",
         default_weight=0.8,
         trigger_words=None,  # V√©rifier sur la page Civitai
         description="Custom LoRA from Civitai"
     ),
     ```

3. **Rebuild le worker** :
   ```bash
   docker-compose restart worker
   ```

4. **V√©rifier que tout est d√©tect√©** :
   ```bash
   curl http://localhost:8009/models | jq '.models[].id'
   # Devrait afficher: "sdxl-base" et "pony-xl-v6"

   curl http://localhost:8009/loras | jq '.loras[].id'
   # Devrait afficher: "anime-style", "character-detail", "civitai-695220"
   ```

5. **G√©n√©rer une image** :
   ```bash
   curl -X POST http://localhost:8009/generate \
     -H "Content-Type: application/json" \
     -d '{
       "prompt": "your prompt here",
       "model": "pony-xl-v6",
       "loras": [{"name": "civitai-695220", "weight": 0.8}],
       "steps": 30,
       "seed": 42
     }' | jq '.job_id'
   ```

6. **R√©cup√©rer l'image** :
   ```bash
   # Remplacer JOB_ID par le job_id retourn√©
   curl http://localhost:8009/image/JOB_ID -o result.png
   ```

---

## üìã Checklist Rapide

- [ ] T√©l√©charger le LoRA dans `./models/mon_lora/`
- [ ] Ajouter le LoRA dans `app/models_config.py`
- [ ] (Optionnel) D√©commenter PonyXL dans `models_config.py`
- [ ] Rebuild: `docker-compose restart worker`
- [ ] V√©rifier: `curl http://localhost:8009/loras`
- [ ] G√©n√©rer: `POST /generate` avec `"model": "pony-xl-v6"` et `"loras": [...]`

---

## ‚ö†Ô∏è Notes Importantes

### VRAM

- **SDXL base** : ~6.5 GB
- **+ 1 LoRA** : +0.3 GB
- **+ 3 LoRAs** : +0.8 GB
- **Limite GPU** : 11 GB (RTX 2080 Ti)

**Recommandation** : Max 3-4 LoRAs simultan√©s

### T√©l√©chargement de Mod√®les

- **HuggingFace** : Auto-t√©l√©chargement au premier usage
- **Civitai/Local** : T√©l√©chargement manuel requis

### Trigger Words

- V√©rifier sur la **page Civitai du LoRA** les trigger words recommand√©s
- Les ajouter dans `trigger_words` pour auto-injection dans le prompt

### DevContainer + Docker-from-Docker

‚ö†Ô∏è **IMPORTANT** : T√©l√©charger les mod√®les **depuis le host Windows**, PAS depuis le DevContainer !

```bash
# ‚ùå NE PAS FAIRE (depuis DevContainer):
wget -O ./models/lora.safetensors https://...

# ‚úÖ FAIRE (depuis Windows ou WSL host):
cd /mnt/c/Users/TON_USER/path/to/imagen
wget -O ./models/mon_lora/lora.safetensors https://...
```

Raison : Docker-from-Docker + volumes bind = namespace isolation.

---

## üéØ Exemple Complet : Setup PonyXL + LoRA en 5 Minutes

```bash
# 1. T√©l√©charger le LoRA (depuis le host)
mkdir -p ./models/my_lora
wget -O ./models/my_lora/model.safetensors \
  "https://civitai.com/api/download/models/695220?type=Model&format=SafeTensor"

# 2. √âditer models_config.py
# - D√©commenter pony-xl-v6
# - Ajouter le LoRA dans AVAILABLE_LORAS

# 3. Rebuild
docker-compose restart worker

# 4. V√©rifier
curl http://localhost:8009/models | jq '.models[].id'

# 5. G√©n√©rer
curl -X POST http://localhost:8009/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "a cute anime pony",
    "model": "pony-xl-v6",
    "loras": [{"name": "my-lora", "weight": 0.8}],
    "seed": 42
  }' | jq -r '.job_id'

# 6. Attendre ~5 min et t√©l√©charger
# curl http://localhost:8009/image/JOB_ID -o result.png
```

---

**Documentation compl√®te** : [API.md](API.md)
**Troubleshooting** : [V2_IMPLEMENTATION_SUMMARY.md](V2_IMPLEMENTATION_SUMMARY.md)
