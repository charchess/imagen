"""
Gestionnaire de mod√®les et LoRAs avec support de t√©l√©chargement automatique
"""

import os
import requests
from pathlib import Path
from typing import Optional, Dict, List
from huggingface_hub import hf_hub_download, scan_cache_dir

from app.config import (
    MODELS_DIR, BASE_MODELS_DIR, LORAS_DIR,
    LORAS_HF_DIR, LORAS_CIVITAI_DIR, VAE_DIR,
    HUGGINGFACE_TOKEN, CIVITAI_API_TOKEN
)


class ModelManager:
    """Gestion des mod√®les et LoRAs avec t√©l√©chargement automatique"""

    @staticmethod
    def is_model_installed(model_path: str, checkpoint_url: Optional[str] = None) -> bool:
        """
        V√©rifie si un mod√®le est install√© localement.

        Args:
            model_path: Chemin HuggingFace (ex: "stabilityai/stable-diffusion-xl-base-1.0")
            checkpoint_url: Nom du fichier checkpoint si applicable

        Returns:
            True si le mod√®le est install√©
        """
        try:
            cache_info = scan_cache_dir(MODELS_DIR)

            # Normaliser le model_path pour correspondre au format du cache
            repo_id = model_path.replace("/", "--")
            expected_repo = f"models--{repo_id}"

            # V√©rifier si le repo existe dans le cache
            for repo in cache_info.repos:
                if expected_repo in str(repo.repo_path):
                    # Si checkpoint sp√©cifique requis, v√©rifier sa pr√©sence
                    if checkpoint_url:
                        for revision in repo.revisions:
                            for file in revision.files:
                                if checkpoint_url in str(file.file_path):
                                    return True
                        return False
                    # Sinon, v√©rifier qu'il y a au moins des fichiers
                    return len(list(repo.revisions)) > 0

            return False
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur v√©rification mod√®le {model_path}: {e}")
            return False

    @staticmethod
    def is_lora_installed(lora_path: str) -> bool:
        """
        V√©rifie si un LoRA est install√© localement.

        Args:
            lora_path: Chemin HuggingFace ou local

        Returns:
            True si le LoRA est install√©
        """
        # Chemin local (ex: ./models/civitai_618068)
        if lora_path.startswith("./"):
            local_path = Path(lora_path)
            return local_path.exists() and any(local_path.glob("*.safetensors"))

        # Chemin HuggingFace
        return ModelManager.is_model_installed(lora_path)

    @staticmethod
    def download_from_civitai(
        model_id: int,
        output_dir: Path,
        filename: Optional[str] = None
    ) -> Optional[Path]:
        """
        T√©l√©charge un mod√®le/LoRA depuis Civitai.

        Args:
            model_id: ID du mod√®le sur Civitai
            output_dir: R√©pertoire de destination
            filename: Nom du fichier de sortie (optionnel)

        Returns:
            Chemin du fichier t√©l√©charg√© ou None si √©chec
        """
        try:
            # API Civitai pour obtenir les infos du mod√®le
            api_url = f"https://civitai.com/api/v1/models/{model_id}"

            headers = {}
            if CIVITAI_API_TOKEN:
                headers["Authorization"] = f"Bearer {CIVITAI_API_TOKEN}"

            print(f"üì• R√©cup√©ration infos Civitai model {model_id}...")
            response = requests.get(api_url, headers=headers)
            response.raise_for_status()

            model_data = response.json()

            # R√©cup√©rer la derni√®re version
            if not model_data.get("modelVersions"):
                print("‚ùå Aucune version disponible")
                return None

            latest_version = model_data["modelVersions"][0]

            # Trouver le fichier principal (.safetensors)
            download_url = None
            original_filename = None

            for file in latest_version.get("files", []):
                if file.get("primary", False) or file["name"].endswith(".safetensors"):
                    download_url = file["downloadUrl"]
                    original_filename = file["name"]
                    break

            if not download_url:
                print("‚ùå Aucun fichier t√©l√©chargeable trouv√©")
                return None

            # Pr√©parer le t√©l√©chargement
            output_dir.mkdir(parents=True, exist_ok=True)
            output_filename = filename or original_filename
            output_path = output_dir / output_filename

            print(f"‚¨áÔ∏è  T√©l√©chargement depuis Civitai: {output_filename}")
            print(f"    URL: {download_url}")

            # T√©l√©charger avec barre de progression
            if CIVITAI_API_TOKEN:
                download_url += f"?token={CIVITAI_API_TOKEN}"

            response = requests.get(download_url, stream=True, headers=headers)
            response.raise_for_status()

            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0

            with open(output_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size > 0:
                            progress = (downloaded / total_size) * 100
                            print(f"    Progression: {progress:.1f}%", end='\r')

            print(f"\n‚úÖ T√©l√©charg√©: {output_path}")
            return output_path

        except Exception as e:
            print(f"‚ùå Erreur t√©l√©chargement Civitai {model_id}: {e}")
            return None

    @staticmethod
    def get_installed_models() -> List[Dict]:
        """
        Liste tous les mod√®les install√©s dans le cache.

        Returns:
            Liste des mod√®les avec leurs infos
        """
        installed = []
        try:
            cache_info = scan_cache_dir(MODELS_DIR)

            for repo in cache_info.repos:
                repo_name = str(repo.repo_path.name).replace("models--", "").replace("--", "/")

                # Calculer la taille totale
                total_size = sum(
                    sum(file.size_on_disk for file in revision.files)
                    for revision in repo.revisions
                )

                installed.append({
                    "repo_id": repo_name,
                    "size_gb": round(total_size / (1024**3), 2),
                    "num_files": sum(len(list(rev.files)) for rev in repo.revisions)
                })
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur listage mod√®les: {e}")

        return installed

    @staticmethod
    def get_installed_loras() -> List[Dict]:
        """
        Liste tous les LoRAs install√©s (HuggingFace + Civitai).

        Returns:
            Liste des LoRAs avec leurs infos
        """
        installed = []

        # LoRAs Civitai
        if LORAS_CIVITAI_DIR.exists():
            for item in LORAS_CIVITAI_DIR.iterdir():
                if item.is_dir():
                    safetensors = list(item.glob("*.safetensors"))
                    if safetensors:
                        total_size = sum(f.stat().st_size for f in safetensors)
                        installed.append({
                            "source": "civitai",
                            "path": str(item.relative_to(MODELS_DIR.parent)),
                            "size_mb": round(total_size / (1024**2), 1),
                            "files": [f.name for f in safetensors]
                        })

        # LoRAs HuggingFace (dans le cache)
        try:
            cache_info = scan_cache_dir(MODELS_DIR)
            for repo in cache_info.repos:
                repo_name = str(repo.repo_path.name).replace("models--", "").replace("--", "/")
                # D√©tecter si c'est un LoRA (contient "lora" dans le nom)
                if "lora" in repo_name.lower():
                    total_size = sum(
                        sum(file.size_on_disk for file in revision.files)
                        for revision in repo.revisions
                    )
                    installed.append({
                        "source": "huggingface",
                        "reference": f"huggingface-{repo_name}",
                        "size_mb": round(total_size / (1024**2), 1),
                        "num_files": sum(len(list(rev.files)) for rev in repo.revisions)
                    })
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur scan LoRAs HuggingFace: {e}")

        return installed
