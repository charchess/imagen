# ğŸ¨ Imagen - Workflow de GÃ©nÃ©ration d'Images

> Documentation technique complÃ¨te du pipeline de gÃ©nÃ©ration SDXL
>
> **Version** : 1.0 | **Date** : 2026-01-30

---

## ğŸ“‹ Table des MatiÃ¨res

1. [Vue d'Ensemble](#vue-densemble)
2. [Architecture du SystÃ¨me](#architecture-du-systÃ¨me)
3. [Workflow DÃ©taillÃ©](#workflow-dÃ©taillÃ©)
4. [ModÃ¨les & Technologies](#modÃ¨les--technologies)
5. [Pipeline de GÃ©nÃ©ration](#pipeline-de-gÃ©nÃ©ration)
6. [Optimisations GPU](#optimisations-gpu)
7. [ParamÃ¨tres de Configuration](#paramÃ¨tres-de-configuration)
8. [Exemples d'Utilisation](#exemples-dutilisation)

---

## ğŸ¯ Vue d'Ensemble

**Imagen** est un service de gÃ©nÃ©ration d'images basÃ© sur **Stable Diffusion XL (SDXL)** avec support de prompts longs et transfert de style via IP-Adapter.

### CaractÃ©ristiques Principales

| Feature | Description | Status |
|---------|-------------|--------|
| ğŸš€ **Async Processing** | GÃ©nÃ©ration non-bloquante via Celery | âœ… Production |
| ğŸ§  **Long Prompts** | Support >77 tokens via Compel | âœ… Production |
| ğŸ­ **Style Transfer** | IP-Adapter pour image de rÃ©fÃ©rence | âœ… Production |
| ğŸ’¾ **GPU Optimized** | Fonctionne sur RTX 2080 Ti (11GB) | âœ… Production |
| ğŸ“Š **Job Tracking** | Status en temps rÃ©el | âœ… Production |
| ğŸ”„ **Auto-Retry** | 3 tentatives sur OOM | âœ… Production |

### SpÃ©cifications Techniques

```
RÃ©solution Native    : 1024x1024 pixels
Format de Sortie     : PNG (16-bit color)
Steps d'InfÃ©rence    : 30 (configurable)
Guidance Scale       : 7.5 (CFG)
Temps Moyen         : ~4-5 minutes par image
VRAM Requis         : ~10-11 GB
Queue Max           : 100 jobs simultanÃ©s
Timeout             : 10 minutes par gÃ©nÃ©ration
```

---

## ğŸ—ï¸ Architecture du SystÃ¨me

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ARCHITECTURE GLOBALE                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   CLIENT    â”‚
          â”‚  (HTTP/S)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ POST /generate
                 â”‚ GET /status/{job_id}
                 â”‚ GET /download/{filename}
                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     FastAPI Server         â”‚
    â”‚    (Port 8000/8009)        â”‚
    â”‚                            â”‚
    â”‚  â€¢ Validation Pydantic     â”‚
    â”‚  â€¢ Queue Management        â”‚
    â”‚  â€¢ StaticFiles Serving     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ Celery Task
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     Redis Broker           â”‚
    â”‚    (Port 6379)             â”‚
    â”‚                            â”‚
    â”‚  â€¢ Task Queue              â”‚
    â”‚  â€¢ Result Backend          â”‚
    â”‚  â€¢ TTL: 1 hour             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ Task Pickup
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Celery Worker (GPU)      â”‚
    â”‚   Concurrency: 1 (solo)    â”‚
    â”‚                            â”‚
    â”‚  â€¢ NVIDIA CUDA Runtime     â”‚
    â”‚  â€¢ ElectraPipeline         â”‚
    â”‚  â€¢ Memory Management       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ Pipeline Execution
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   SDXL Pipeline            â”‚
    â”‚   (GPU Accelerated)        â”‚
    â”‚                            â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚  1. Compel Encoding  â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚             â–¼              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚  2. IP-Adapter (opt) â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚             â–¼              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚  3. UNet Denoising   â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚             â–¼              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚  4. VAE Decoding     â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚             â–¼              â”‚
    â”‚        PNG Image           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ Save to Disk
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Docker Volume â”‚
         â”‚   /outputs/   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Workflow DÃ©taillÃ©

### Phase 1 : RÃ©ception de la RequÃªte

```python
POST /generate
{
    "prompt": "a majestic dragon flying over mountains at sunset",
    "negative_prompt": "blurry, low quality, distorted, ugly",
    "ip_strength": 0.0
}
```

**Validations** :
- âœ… Schema Pydantic (`GenerationRequest`)
- âœ… Queue capacity check (<100 jobs)
- âœ… Redis connection health

**RÃ©ponse ImmÃ©diate** :
```json
{
    "job_id": "7f2b0887-3cdf-46ff-b83b-ff7685ac5b23",
    "status": "queued",
    "message": "TÃ¢che en file d'attente. Position estimÃ©e: 3"
}
```

---

### Phase 2 : Task Queue & Distribution

```
Redis Queue
â”œâ”€ Priority: FIFO (First In First Out)
â”œâ”€ Serialization: JSON
â”œâ”€ Retry Policy: 3 attempts, 10s backoff
â””â”€ Timeout: 600s (10 minutes)

Celery Worker Pool
â”œâ”€ Pool Type: solo (single-threaded)
â”œâ”€ Concurrency: 1 task at a time
â”œâ”€ Prefetch: 1 (no pre-loading)
â””â”€ GPU: CUDA_VISIBLE_DEVICES=0
```

---

### Phase 3 : Pipeline de GÃ©nÃ©ration

#### 3.1 - Initialisation (Singleton Pattern)

```python
ElectraPipeline Instance
â”œâ”€ Lazy Loading (first use only)
â”œâ”€ GPU Detection (cuda/cpu)
â”œâ”€ Model Loading
â”‚   â”œâ”€ SDXL Base (6.9 GB)
â”‚   â”œâ”€ VAE Fix (335 MB)
â”‚   â””â”€ Text Encoders (2x)
â””â”€ Compel Setup (dual encoders)
```

#### 3.2 - Prompt Processing avec Compel

**Pourquoi Compel ?**

CLIP (text encoder de base) limite les prompts Ã  **77 tokens**. Compel permet de dÃ©passer cette limite.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COMPEL DUAL ENCODER SYSTEM             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input Prompt (unlimited length)
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                 â–¼                 â–¼
   Text Encoder 1    Text Encoder 2    Pooling
   (OpenCLIP         (OpenAI CLIP      (Global
    ViT-bigG)         ViT-L)            Features)
         â”‚                 â”‚                 â”‚
         â–¼                 â–¼                 â–¼
    Embeddings 1      Embeddings 2      Pooled Embeds
    (77x768)          (77x1280)         (1280)
         â”‚                 â”‚                 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                  Concatenated Embeddings
                  (Ready for UNet)
```

**Code** :
```python
# Tokenization + Embedding
conditioning, pooled = self.compel(prompt)
neg_conditioning, neg_pooled = self.compel(negative_prompt)
```

**RÃ©sultat** :
- âœ… Prompts de **548+ caractÃ¨res** supportÃ©s
- âœ… Nuances sÃ©mantiques prÃ©servÃ©es
- âœ… Meilleure cohÃ©rence image/texte

#### 3.3 - IP-Adapter (Optionnel)

**ActivÃ© si** : `ip_strength > 0.0` et image de rÃ©fÃ©rence fournie

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              IP-ADAPTER ARCHITECTURE                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Reference Image (electra_ref.png)
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ CLIP Vision  â”‚
  â”‚  Encoder     â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   Image Embeddings
   (1 x 1280)
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Projection  â”‚
  â”‚  Network     â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   Projected Features
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                     â”‚
         â–¼                     â–¼
   Cross-Attention      +   Text Embeddings
   (in UNet layers)          (from Compel)
         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â–¼
                        Fused Features
                        (Style + Prompt)
```

**ParamÃ¨tres** :
- `ip_strength` : 0.0 (dÃ©sactivÃ©) â†’ 1.0 (style complet)
- RecommandÃ© : 0.5-0.7 pour Ã©quilibre prompt/style

**Code** :
```python
if reference_image_path and Path(reference_image_path).exists():
    ref_image = Image.open(reference_image_path).convert("RGB")
    self.pipe.load_ip_adapter(IP_ADAPTER_MODEL, ...)
    self.pipe.set_ip_adapter_scale(ip_strength)
    ip_args = {"ip_adapter_image": ref_image}
```

#### 3.4 - UNet Denoising (CÅ“ur de SDXL)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           SDXL DENOISING PROCESS (30 STEPS)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 0: Pure Noise Latent (128x128x4)
   â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  â”‚  UNet 2D Condition Model (2.6B params)  â”‚
   â”‚  â”‚                                          â”‚
   â”‚  â”‚  Input:                                  â”‚
   â”‚  â”‚  â”œâ”€ Noisy latent (t=1000 â†’ t=0)         â”‚
   â”‚  â”‚  â”œâ”€ Text embeddings (conditioning)      â”‚
   â”‚  â”‚  â”œâ”€ Timestep embedding                  â”‚
   â”‚  â”‚  â””â”€ IP features (if enabled)            â”‚
   â”‚  â”‚                                          â”‚
   â”‚  â”‚  Architecture:                           â”‚
   â”‚  â”‚  â”œâ”€ Down blocks (3x)                    â”‚
   â”‚  â”‚  â”œâ”€ Mid block (transformer)             â”‚
   â”‚  â”‚  â”œâ”€ Up blocks (3x)                      â”‚
   â”‚  â”‚  â””â”€ Cross-attention layers              â”‚
   â”‚  â”‚                                          â”‚
   â”‚  â”‚  Output:                                 â”‚
   â”‚  â”‚  â””â”€ Noise prediction                    â”‚
   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚                    â”‚
   â”‚                    â–¼
   â”‚         Noise Removal (DDPM)
   â”‚         Less noisy latent
   â”‚                    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ (repeat 30 times)
              â”‚
              â–¼
   Clean Latent (128x128x4)
```

**Scheduler** : DPMSolver++ (default SDXL)
- Sampling steps : 30
- Guidance scale : 7.5 (CFG - Classifier-Free Guidance)

**Classifier-Free Guidance** :
```
predicted_noise = unconditional_noise + 7.5 * (conditional_noise - unconditional_noise)
```
â†’ Plus le CFG est Ã©levÃ©, plus l'image suit le prompt (mais moins de crÃ©ativitÃ©)

**Code** :
```python
image = self.pipe(
    prompt_embeds=conditioning,
    pooled_prompt_embeds=pooled,
    negative_prompt_embeds=neg_conditioning,
    negative_pooled_prompt_embeds=neg_pooled,
    num_inference_steps=30,
    guidance_scale=7.5,
    height=1024,
    width=1024,
    **ip_args
).images[0]
```

#### 3.5 - VAE Decoding

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VAE DECODER (FP16 FIX)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Latent Space (128x128x4)
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ VAE Decoder  â”‚
  â”‚ (madebyollin)â”‚
  â”‚              â”‚
  â”‚ Features:    â”‚
  â”‚ â€¢ FP16 opt   â”‚
  â”‚ â€¢ Slicing    â”‚
  â”‚ â€¢ Tiling     â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  Pixel Space (1024x1024x3)
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Clamp [0,1]  â”‚
  â”‚ â†’ uint8      â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   PNG Image (1-2 MB)
```

**Pourquoi le VAE Fix ?**

Le VAE standard SDXL peut produire des **artefacts noirs** en FP16. Le modÃ¨le `madebyollin/sdxl-vae-fp16-fix` corrige ce problÃ¨me.

**Optimisations** :
- **VAE Slicing** : Traite l'image par batches de canaux
- **VAE Tiling** : DÃ©coupe l'image en tuiles 512x512

---

## ğŸ§  ModÃ¨les & Technologies

### Tableau RÃ©capitulatif

| ModÃ¨le | Source | Taille | RÃ´le | ParamÃ¨tres |
|--------|--------|--------|------|------------|
| **SDXL Base 1.0** | `stabilityai/stable-diffusion-xl-base-1.0` | 6.9 GB | UNet + Text Encoders | 2.6B (UNet) |
| **VAE FP16 Fix** | `madebyollin/sdxl-vae-fp16-fix` | 335 MB | Decoder latentâ†’pixel | 83M |
| **IP-Adapter SDXL** | `h94/IP-Adapter` | 1.8 GB | Style transfer | 358M |
| **Compel** | `damian0815/compel` | Library | Long prompts | N/A |
| **PyTorch** | `pytorch.org` | N/A | ML Framework | N/A |
| **Diffusers** | `huggingface/diffusers` | N/A | Pipeline | N/A |

### Architecture des Text Encoders

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            SDXL DUAL TEXT ENCODER SYSTEM              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Text Encoder 1 (OpenCLIP ViT-bigG/14)
â”œâ”€ Vocabulary: 49,408 tokens
â”œâ”€ Hidden Size: 1,280
â”œâ”€ Layers: 32
â”œâ”€ Attention Heads: 20
â”œâ”€ Parameters: 354M
â””â”€ Output: [batch, 77, 1280]

Text Encoder 2 (OpenAI CLIP ViT-L/14)
â”œâ”€ Vocabulary: 49,408 tokens
â”œâ”€ Hidden Size: 768
â”œâ”€ Layers: 12
â”œâ”€ Attention Heads: 12
â”œâ”€ Parameters: 123M
â””â”€ Output: [batch, 77, 768]

Fusion Strategy
â”œâ”€ Concatenation (channel-wise)
â”œâ”€ Pooling (global features)
â””â”€ Cross-attention in UNet
```

### UNet Architecture (SDXL)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SDXL UNET 2D ARCHITECTURE                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input: [batch, 4, 128, 128]
   â”‚
   â”œâ”€ Conv In (320 channels)
   â”‚
   â”œâ”€ Down Block 1 (320 â†’ 320)
   â”‚   â”œâ”€ ResNet Ã— 2
   â”‚   â”œâ”€ Transformer Ã— 2 (Cross-Attention)
   â”‚   â””â”€ Downsample
   â”‚
   â”œâ”€ Down Block 2 (320 â†’ 640)
   â”‚   â”œâ”€ ResNet Ã— 2
   â”‚   â”œâ”€ Transformer Ã— 2
   â”‚   â””â”€ Downsample
   â”‚
   â”œâ”€ Down Block 3 (640 â†’ 1280)
   â”‚   â”œâ”€ ResNet Ã— 2
   â”‚   â””â”€ Transformer Ã— 10
   â”‚
   â”œâ”€ Mid Block (1280)
   â”‚   â”œâ”€ ResNet Ã— 1
   â”‚   â”œâ”€ Transformer Ã— 10
   â”‚   â””â”€ ResNet Ã— 1
   â”‚
   â”œâ”€ Up Block 1 (1280 â†’ 1280)
   â”‚   â”œâ”€ ResNet Ã— 3
   â”‚   â”œâ”€ Transformer Ã— 10
   â”‚   â””â”€ Upsample
   â”‚
   â”œâ”€ Up Block 2 (1280 â†’ 640)
   â”‚   â”œâ”€ ResNet Ã— 3
   â”‚   â”œâ”€ Transformer Ã— 2
   â”‚   â””â”€ Upsample
   â”‚
   â”œâ”€ Up Block 3 (640 â†’ 320)
   â”‚   â”œâ”€ ResNet Ã— 3
   â”‚   â””â”€ Transformer Ã— 2
   â”‚
   â””â”€ Conv Out
       â”‚
       â–¼
Output: [batch, 4, 128, 128]

Total Parameters: ~2.6 Billion
```

---

## âš¡ Optimisations GPU

### StratÃ©gie de Gestion MÃ©moire

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         GPU MEMORY MANAGEMENT (11GB RTX 2080 Ti)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Technique 1: Model CPU Offload
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPU VRAM (11 GB)              CPU RAM (64+ GB)      â”‚
â”‚                                                     â”‚
â”‚  Active Layer                 Idle Layers          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ UNet L12 â”‚ â—„â”€â”€â”€â”€swapâ”€â”€â”€â”€â”€â–ºâ”‚ UNet L1  â”‚          â”‚
â”‚  â”‚ (500 MB) â”‚                â”‚ (500 MB) â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                     â”‚
â”‚  Latent + Activations         Models Cache         â”‚
â”‚  (2-3 GB)                     (6 GB)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Technique 2: VAE Slicing
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Standard:                  Sliced:                  â”‚
â”‚                                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”         â”‚
â”‚ â”‚  Full Image     â”‚        â”‚Sliceâ”‚ â”‚Sliceâ”‚         â”‚
â”‚ â”‚  1024x1024x3    â”‚   â†’    â”‚ 1   â”‚â†’â”‚  2  â”‚â†’ ...   â”‚
â”‚ â”‚  (10 GB VRAM)   â”‚        â”‚512x â”‚ â”‚512x â”‚         â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                            (2 GB each)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Technique 3: VAE Tiling
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Image divisÃ©e en tuiles overlapping 512x512       â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ T1   â”‚ T2   â”‚ T3   â”‚ T4   â”‚                     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤                     â”‚
â”‚  â”‚ T5   â”‚ T6   â”‚ T7   â”‚ T8   â”‚   Processed         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤   sequentially      â”‚
â”‚  â”‚ T9   â”‚ T10  â”‚ T11  â”‚ T12  â”‚   (1-2 GB each)     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤                     â”‚
â”‚  â”‚ T13  â”‚ T14  â”‚ T15  â”‚ T16  â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                     â”‚
â”‚  Blend overlaps â†’ seamless image                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration PyTorch

```python
# Environment Variables
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'

# Pipeline Optimizations
self.pipe.enable_model_cpu_offload()  # Dynamic layer swapping
self.pipe.enable_vae_slicing()        # Batch processing
self.pipe.enable_vae_tiling()         # Spatial tiling

# Memory Cleanup (after generation)
torch.cuda.empty_cache()
gc.collect()
```

### Profil VRAM Typique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            VRAM USAGE DURING GENERATION               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase                        VRAM Used   Cumulative
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Idle (models loaded)         6.5 GB      6.5 GB
Text Encoding (Compel)       +0.3 GB     6.8 GB
IP-Adapter (if enabled)      +0.5 GB     7.3 GB
UNet Forward Pass (peak)     +3.2 GB    10.5 GB
VAE Decoding (with tiling)   +0.4 GB    10.9 GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Peak VRAM                               10.9 GB âœ…

Safety Margin: 0.1 GB (11 GB total)
```

---

## âš™ï¸ ParamÃ¨tres de Configuration

### Fichier : `app/config.py`

```python
# ModÃ¨les
SDXL_MODEL = "stabilityai/stable-diffusion-xl-base-1.0"
VAE_MODEL = "madebyollin/sdxl-vae-fp16-fix"
IP_ADAPTER_MODEL = "h94/IP-Adapter"
IP_ADAPTER_SUBFOLDER = "sdxl_models"
IP_ADAPTER_WEIGHT = "ip-adapter_sdxl.bin"

# Chemins
MODELS_DIR = Path("models")
OUTPUTS_DIR = Path("outputs")
REFERENCE_IMAGE = Path("reference/electra_ref.png")

# ParamÃ¨tres de GÃ©nÃ©ration
DEFAULT_STEPS = 30           # 20-50 recommandÃ©
GUIDANCE_SCALE = 7.5         # 5.0-15.0 (â†‘ = plus fidÃ¨le au prompt)
IMAGE_SIZE = (1024, 1024)    # Native SDXL resolution

# Queue & Worker
REDIS_URL = "redis://localhost:6379/0"
MAX_QUEUE_SIZE = 100
CELERY_TASK_TIMEOUT = 600    # 10 minutes
CELERY_RESULT_EXPIRES = 3600 # 1 hour
```

### Tuning des ParamÃ¨tres

| ParamÃ¨tre | Effet si AugmentÃ© | Recommandation |
|-----------|-------------------|----------------|
| **Steps** | + QualitÃ©, + Temps | 30-40 (sweet spot) |
| **Guidance Scale** | + AdhÃ©rence prompt, - CrÃ©ativitÃ© | 7.5 (dÃ©faut), 5-10 (crÃ©atif), 10-15 (prÃ©cis) |
| **IP Strength** | + Style rÃ©fÃ©rence, - Prompt | 0.5-0.7 (Ã©quilibrÃ©) |
| **Resolution** | + DÃ©tails, ++ VRAM | 1024x1024 (optimal SDXL) |

---

## ğŸ“Š Exemples d'Utilisation

### Exemple 1 : GÃ©nÃ©ration Simple

**RequÃªte** :
```bash
curl -X POST http://localhost:8009/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "a majestic dragon flying over snow-capped mountains at golden hour, cinematic lighting, highly detailed, 8k",
    "negative_prompt": "blurry, low quality, distorted, ugly, bad anatomy",
    "ip_strength": 0.0
  }'
```

**RÃ©ponse** :
```json
{
  "job_id": "abc123...",
  "status": "queued",
  "message": "TÃ¢che en file d'attente. Position estimÃ©e: 1"
}
```

**Polling** :
```bash
# VÃ©rifier le statut
curl http://localhost:8009/status/abc123...

# RÃ©ponse (en cours)
{
  "job_id": "abc123...",
  "status": "PROGRESS",
  "meta": {
    "current": 15,
    "total": 30,
    "percent": 50
  }
}

# RÃ©ponse (terminÃ©)
{
  "job_id": "abc123...",
  "status": "SUCCESS",
  "result": {
    "status": "success",
    "filename": "20260130_123456_abc123.png",
    "path": "outputs/20260130_123456_abc123.png",
    "url": "/outputs/20260130_123456_abc123.png"
  }
}
```

**TÃ©lÃ©chargement** :
```bash
curl http://localhost:8009/outputs/20260130_123456_abc123.png --output dragon.png
```

---

### Exemple 2 : Style Transfer avec IP-Adapter

**Setup** :
1. Placer image de rÃ©fÃ©rence : `reference/my_style.png`
2. Modifier `config.py` : `REFERENCE_IMAGE = Path("reference/my_style.png")`

**RequÃªte** :
```bash
curl -X POST http://localhost:8009/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "a futuristic cityscape at night, neon lights, cyberpunk aesthetic",
    "negative_prompt": "blurry, low quality",
    "ip_strength": 0.65
  }'
```

**RÃ©sultat** :
- Image gÃ©nÃ©rÃ©e avec le style de `my_style.png` (65%)
- Prompt textuel (35%)
- Fusion harmonieuse des deux influences

---

### Exemple 3 : Prompt Long (>77 tokens)

**Prompt** (548 caractÃ¨res) :
```
"A breathtaking fantasy landscape featuring an ancient elven city built into
massive crystalline trees that glow with bioluminescent light, suspended
bridges of living wood connect towering structures, waterfalls cascade from
floating islands in the sky, mystical creatures soar between the branches,
volumetric god rays pierce through the canopy, magical runes shimmer on
stone archways, ethereal mist swirls around the base of the trees, distant
mountains frame the scene, golden hour lighting with purple and blue tones,
ultra detailed, trending on artstation, 8k, cinematic composition"
```

**Traitement** :
```
Original: 548 chars â†’ ~110 tokens
CLIP Standard: Only first 77 tokens âŒ
Compel: Full 110 tokens processed âœ…

RÃ©sultat: Image respecte TOUS les dÃ©tails du prompt
```

---

## ğŸ“ˆ MÃ©triques de Performance

### Temps de GÃ©nÃ©ration

| Configuration | Steps | RÃ©solution | Temps Moyen | VRAM Peak |
|--------------|-------|------------|-------------|-----------|
| Rapide | 20 | 1024x1024 | ~2.5 min | 9.2 GB |
| Standard | 30 | 1024x1024 | ~4.3 min | 10.5 GB |
| QualitÃ© | 50 | 1024x1024 | ~7.1 min | 10.8 GB |
| HD | 30 | 1536x1536 | ~9.2 min | OOM âŒ |

### DÃ©bit (Throughput)

```
Worker Configuration: 1 concurrent task (solo pool)

Throughput ThÃ©orique:
- 1 gÃ©nÃ©ration / 4.3 min
- ~14 images / heure
- ~336 images / jour (24/7)

Queue Management:
- Max 100 jobs en attente
- Position estimÃ©e affichÃ©e au client
- 503 Service Unavailable si queue pleine
```

---

## ğŸ” Troubleshooting

### Erreurs Courantes

| Erreur | Cause | Solution |
|--------|-------|----------|
| `CUDA out of memory` | VRAM insuffisante | RÃ©duire steps ou activer optimisations |
| `Queue pleine (503)` | >100 jobs en attente | Attendre ou augmenter workers |
| `Timeout (10min)` | GÃ©nÃ©ration trop complexe | Augmenter `CELERY_TASK_TIMEOUT` |
| `Artefacts noirs` | VAE non-fixÃ© | VÃ©rifier `VAE_MODEL` = fix version |
| `Prompt tronquÃ©` | Compel dÃ©sactivÃ© | VÃ©rifier init pipeline |

### Logs de Diagnostic

```bash
# Worker logs (gÃ©nÃ©ration)
docker-compose logs -f worker

# API logs (requÃªtes)
docker-compose logs -f api

# Redis logs (queue)
docker-compose logs -f redis

# Monitoring Celery
make flower  # http://localhost:5555
```

---

## ğŸ“š RÃ©fÃ©rences

### Documentation Officielle

- [Stable Diffusion XL Paper](https://arxiv.org/abs/2307.01952)
- [Diffusers Library](https://huggingface.co/docs/diffusers)
- [Compel GitHub](https://github.com/damian0815/compel)
- [IP-Adapter Paper](https://arxiv.org/abs/2308.06721)

### ModÃ¨les HuggingFace

- [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
- [madebyollin/sdxl-vae-fp16-fix](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)
- [h94/IP-Adapter](https://huggingface.co/h94/IP-Adapter)

### Technologies

- [FastAPI](https://fastapi.tiangolo.com/)
- [Celery](https://docs.celeryq.dev/)
- [PyTorch](https://pytorch.org/)
- [Redis](https://redis.io/)

---

## ğŸ“ Changelog

### Version 1.0 (2026-01-30)
- âœ… Pipeline SDXL opÃ©rationnel
- âœ… Support Compel pour prompts longs
- âœ… IP-Adapter intÃ©grÃ©
- âœ… Optimisations GPU (11GB)
- âœ… API REST complÃ¨te
- âœ… Worker Celery async
- âœ… Documentation technique

---

**Imagen** | Made with â¤ï¸ using SDXL
