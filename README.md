# ğŸ¨ Imagen - AI Image Generation API

> Service de gÃ©nÃ©ration d'images basÃ© sur Stable Diffusion XL avec support de prompts longs et style transfer

[![Production Ready](https://img.shields.io/badge/status-production%20ready-success)]()
[![SDXL](https://img.shields.io/badge/model-SDXL%201.0-blue)]()
[![GPU](https://img.shields.io/badge/GPU-RTX%202080%20Ti-green)]()
[![API](https://img.shields.io/badge/API-REST-orange)]()

---

## âœ¨ FonctionnalitÃ©s

- ğŸš€ **GÃ©nÃ©ration Async** - Queue non-bloquante via Celery + Redis
- ğŸ§  **Prompts Longs** - Support illimitÃ© via Compel (>77 tokens)
- ğŸ­ **Style Transfer** - IP-Adapter pour images de rÃ©fÃ©rence
- ğŸ’¾ **GPU OptimisÃ©** - Fonctionne sur RTX 2080 Ti (11GB VRAM)
- ğŸ“Š **Job Tracking** - Suivi en temps rÃ©el de la gÃ©nÃ©ration
- ğŸ”„ **Auto-Retry** - 3 tentatives automatiques sur erreur
- ğŸ³ **Docker Ready** - DÃ©ploiement conteneurisÃ© avec NVIDIA runtime

---

## ğŸš€ Quick Start

### PrÃ©requis

- Docker + Docker Compose
- NVIDIA GPU avec CUDA support
- 11+ GB VRAM

### Installation

```bash
# 1. Cloner le repo
git clone <repo-url>
cd imagen

# 2. DÃ©marrer les services
docker-compose up -d

# 3. VÃ©rifier le health check
curl http://localhost:8009/health
```

### PremiÃ¨re GÃ©nÃ©ration

```bash
# CrÃ©er une gÃ©nÃ©ration
curl -X POST http://localhost:8009/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "a beautiful sunset over mountains",
    "negative_prompt": "blurry, low quality"
  }' | jq -r '.job_id'

# RÃ©ponse: 7f2b0887-3cdf-46ff-b83b-ff7685ac5b23

# TÃ©lÃ©charger l'image (aprÃ¨s ~5 minutes)
curl http://localhost:8009/image/7f2b0887-3cdf-46ff-b83b-ff7685ac5b23 \
  -o sunset.png
```

---

## ğŸ“– Documentation

### ğŸ“˜ Pour les Utilisateurs

| Document | Description |
|----------|-------------|
| **[API.md](API.md)** | ğŸ“˜ RÃ©fÃ©rence API complÃ¨te - Endpoints, schÃ©mas, exemples |
| **[API_UPDATES.md](API_UPDATES.md)** | ğŸš€ Nouvelles fonctionnalitÃ©s et mises Ã  jour |

### ğŸ”§ Pour les DÃ©veloppeurs

| Document | Description |
|----------|-------------|
| **[WORKFLOW.md](WORKFLOW.md)** | ğŸ”„ Architecture technique dÃ©taillÃ©e - Workflow, modÃ¨les, optimisations |
| **[PONY_XL_INTEGRATION.md](PONY_XL_INTEGRATION.md)** | ğŸ¦„ Guide d'implÃ©mentation PonyXL v6 + LoRA/LyCORIS |
| **[CLAUDE.md](CLAUDE.md)** | ğŸ“– Documentation projet complÃ¨te - Vue d'ensemble et rÃ©fÃ©rence |

---

## ğŸ¯ Exemples d'Utilisation

### Python

```python
import requests
import time

API_URL = "http://localhost:8009"

# CrÃ©er une gÃ©nÃ©ration
response = requests.post(f"{API_URL}/generate", json={
    "prompt": "a majestic dragon flying over mountains",
    "negative_prompt": "blurry, low quality"
})
job_id = response.json()["job_id"]

# Polling jusqu'Ã  succÃ¨s
while True:
    response = requests.get(f"{API_URL}/image/{job_id}")
    if response.status_code == 200:
        with open("dragon.png", "wb") as f:
            f.write(response.content)
        print("âœ… Image tÃ©lÃ©chargÃ©e!")
        break
    time.sleep(5)
```

### Bash

```bash
#!/bin/bash

# Fonction helper
generate_image() {
  local prompt="$1"
  local output="$2"

  # CrÃ©er job
  JOB_ID=$(curl -s -X POST http://localhost:8009/generate \
    -H "Content-Type: application/json" \
    -d "{\"prompt\": \"$prompt\"}" \
    | jq -r '.job_id')

  echo "Job crÃ©Ã©: $JOB_ID"

  # Polling automatique
  while ! curl -f -o "$output" http://localhost:8009/image/$JOB_ID 2>/dev/null; do
    echo "â³ En cours..."
    sleep 5
  done

  echo "âœ… Image sauvegardÃ©e: $output"
}

# Utilisation
generate_image "a cyberpunk city at night" "city.png"
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI     â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚  Redis  â”‚
â”‚  (Port 8009) â”‚       â”‚ (Queue) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Celery Task
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Celery Workerâ”‚â”€â”€â”€â”€â”€â”€â–ºâ”‚ SDXL Pipelineâ”‚
â”‚  (GPU Solo)  â”‚       â”‚   + Compel   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ + IP-Adapter â”‚
       â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Docker Volumeâ”‚
â”‚  /outputs/   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Composants** :
- **FastAPI** : API REST (port 8009)
- **Redis** : Message broker & result backend
- **Celery Worker** : ExÃ©cution GPU (concurrency=1)
- **SDXL Pipeline** : GÃ©nÃ©ration d'images (1024x1024)

---

## ğŸ› ï¸ Commandes Utiles

### Makefile

```bash
make dev        # Lancer FastAPI avec reload
make worker     # Lancer Celery worker localement
make flower     # Dashboard monitoring Celery (port 5555)
make up         # Docker Compose startup
make down       # Docker Compose shutdown
make gpu        # VÃ©rifier statut GPU (nvidia-smi)
```

### Docker Compose

```bash
# DÃ©marrer
docker-compose up -d

# ArrÃªter
docker-compose down

# Logs
docker-compose logs -f api
docker-compose logs -f worker

# Rebuild aprÃ¨s changement de code
docker-compose down
docker-compose build
docker-compose up -d
```

---

## ğŸ“Š SpÃ©cifications Techniques

### ModÃ¨les

| ModÃ¨le | Taille | RÃ´le |
|--------|--------|------|
| SDXL Base 1.0 | 6.9 GB | GÃ©nÃ©ration principale |
| VAE FP16 Fix | 335 MB | DÃ©codage sans artefacts |
| IP-Adapter SDXL | 1.8 GB | Transfert de style |

### Performance

| MÃ©trique | Valeur |
|----------|--------|
| **Temps de gÃ©nÃ©ration** | ~4-5 minutes |
| **VRAM utilisÃ©e** | ~10-11 GB |
| **RÃ©solution** | 1024x1024 pixels |
| **Format** | PNG (~1-2 MB) |
| **Throughput** | ~14 images/heure |

### Limites

| Limite | Valeur |
|--------|--------|
| **Queue max** | 100 jobs |
| **Timeout** | 10 minutes/gÃ©nÃ©ration |
| **Result TTL** | 1 heure |
| **Workers** | 1 (solo pool) |

---

## ğŸ”§ Configuration

### Environnement

```bash
# Redis
REDIS_URL=redis://redis:6379/0

# GPU
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# Celery
CELERY_WORKER_CONCURRENCY=1
```

### ParamÃ¨tres de GÃ©nÃ©ration

```python
# app/config.py

DEFAULT_STEPS = 30           # 20-50 recommandÃ©
GUIDANCE_SCALE = 7.5         # 5.0-15.0 (CFG)
IMAGE_SIZE = (1024, 1024)    # RÃ©solution native SDXL
MAX_QUEUE_SIZE = 100         # Limite de queue
```

---

## ğŸ› DÃ©pannage

### API ne rÃ©pond pas

```bash
# VÃ©rifier les conteneurs
docker-compose ps

# VÃ©rifier les logs
docker-compose logs api --tail=50

# RedÃ©marrer
docker-compose restart api
```

### Queue pleine (503)

```bash
# VÃ©rifier le nombre de jobs en attente
docker-compose exec api python3 -c "
from app.worker import celery_app
inspector = celery_app.control.inspect()
print('Active:', inspector.active())
print('Scheduled:', inspector.scheduled())
"

# Attendre que la queue se vide
```

### GÃ©nÃ©ration Ã©chouÃ©e (OOM)

```bash
# VÃ©rifier les logs du worker
docker-compose logs worker --tail=100

# La tÃ¢che est automatiquement retentÃ©e 3 fois
```

### Images non visibles localement (DevContainer)

```bash
# Les images SONT dans le volume Docker
docker run --rm -v /workspaces/imagen/outputs:/outputs alpine ls -lh /outputs/

# Copier vers local
docker run --rm -v /workspaces/imagen/outputs:/src -v ${PWD}:/dest \
  alpine sh -c "cp /src/*.png /dest/"
```

---

## ğŸš§ Roadmap

### âœ… Version 1.0 (Actuelle)

- [x] SDXL Base 1.0
- [x] Support prompts longs (Compel)
- [x] IP-Adapter
- [x] API REST complÃ¨te
- [x] Download direct par job ID

### ğŸ“‹ Version 2.0 (PlanifiÃ©e)

- [ ] PonyXL v6 support
- [ ] LoRA/LyCORIS dynamiques
- [ ] Multi-modÃ¨les configurables
- [ ] Seeds reproductibles
- [ ] Steps/CFG configurables par requÃªte
- [ ] Endpoints `/models` et `/loras`

Voir [PONY_XL_INTEGRATION.md](PONY_XL_INTEGRATION.md) pour dÃ©tails.

---

## ğŸ“„ Licence

Ce projet utilise des modÃ¨les open-source :

- **SDXL Base 1.0** : [CreativeML Open RAIL++-M License](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
- **IP-Adapter** : [Apache 2.0](https://github.com/tencent-ailab/IP-Adapter)
- **Compel** : [MIT](https://github.com/damian0815/compel)

---

## ğŸ™ Remerciements

- [Stability AI](https://stability.ai/) - SDXL Base 1.0
- [Tencent AI Lab](https://github.com/tencent-ailab) - IP-Adapter
- [Damian Stewart](https://github.com/damian0815) - Compel
- [HuggingFace](https://huggingface.co/) - Diffusers Library
- [madebyollin](https://huggingface.co/madebyollin) - VAE FP16 Fix

---

## ğŸ“ Support

### Documentation

- **API Reference** : [API.md](API.md)
- **Technical Workflow** : [WORKFLOW.md](WORKFLOW.md)
- **Project Overview** : [CLAUDE.md](CLAUDE.md)

### Monitoring

- **Celery Dashboard** : http://localhost:5555 (`make flower`)
- **API Health** : http://localhost:8009/health
- **Logs** : `docker-compose logs -f`

---

**Version** : 1.0
**Status** : Production Ready âœ…
**Last Updated** : 2026-01-30
